{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Simulations\n",
    "This notebook describes the basic method used to construct the Monte Carlo Simulation presented in chapter 6 of Applied Math for Security. Much of the code is described in detail throughout the chapter so the descriptions here are meant to supplement the text.\n",
    "\n",
    "The user_to_series function has been taken from the code presented in chapter 5 but essentially it loads the nested JSON user object into a Pandas Series which can be appended to the main DataFrame object.\n",
    "The unique function is a (poor) implementation to find all the unique items in a list. This could be replaced by a better implementation from a library like numpy.unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "import graph_funcs as ext\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import json\n",
    "\n",
    "def user_to_series(dict_obj):\n",
    "    \"\"\"Convert a nested JSON user to a flat pandas series\"\"\"\n",
    "    renamed = {}\n",
    "    for k in dict_obj.keys():\n",
    "        nk = \"user_%s\" % k\n",
    "        v = dict_obj[k]\n",
    "        renamed[nk] = v\n",
    "    ret = pd.Series(renamed)\n",
    "    return ret\n",
    "\n",
    "def unique(bag):\n",
    "    ret = []\n",
    "    for i in bag:\n",
    "        #print(i)\n",
    "        if i not in ret:\n",
    "            ret.append(i)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the posts data using the same method presented in chapter 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28034 entries, 0 to 28033\n",
      "Data columns (total 16 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       28034 non-null  int64  \n",
      " 1   id_str                   28034 non-null  object \n",
      " 2   created_at               28034 non-null  object \n",
      " 3   text                     28034 non-null  object \n",
      " 4   source                   28034 non-null  object \n",
      " 5   retweet_count            28034 non-null  int64  \n",
      " 6   liked_count              28034 non-null  int64  \n",
      " 7   in_reply_to_user_id      10302 non-null  object \n",
      " 8   in_reply_to_tweet_id     10302 non-null  float64\n",
      " 9   in_reply_to_user_id_str  10302 non-null  object \n",
      " 10  in_reply_to_screen_name  10302 non-null  object \n",
      " 11  user_id                  28034 non-null  object \n",
      " 12  user_screen_name         28034 non-null  object \n",
      " 13  user_location            28034 non-null  object \n",
      " 14  user_description         28034 non-null  object \n",
      " 15  user_url                 28034 non-null  object \n",
      "dtypes: float64(1), int64(3), object(12)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "series_data = [] # 1 JSON object per post object\n",
    "with open(\"fake_posts.json\") as data:\n",
    "    text = data.read().strip()\n",
    "    rows = text.split(\"\\n\")  # JSON objects stored as list of strings\n",
    "for row in rows:\n",
    "    obj = json.loads(row) # Converted row string to JSON object\n",
    "    series_data.append(obj) # Add to JSON list\n",
    "post_df = pd.DataFrame(series_data) # 1 row per JSON obj\n",
    "post_df = pd.concat([post_df, post_df['user'].apply(user_to_series)], axis=1)\n",
    "# Now the data is flattened. We remove the field containing the JSON object\n",
    "post_df.drop(\"user\", axis=1, inplace=True)\n",
    "post_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code from listing 6-2 is a deterministic simulation where the a message is passed from user to user. The state machine is deterministic although it still uses random choice, because if we choose an input like send the action succeeds 100% of the time. Determinism refers to the actions themselves and not to the result as a whole (which will be stochastic). in the real world, calls may fail. emails may bounce. messages may not successfully be delivered. You may want to extend this code to add cases where a state transition may fail with some probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message terminated at node bethanyturner in 2 steps\n",
      "Message terminated at node fbrown in 3 steps\n",
      "Message terminated at node fbrown in 5 steps\n",
      "Message terminated at node bethanyturner in 2 steps\n",
      "Message terminated at node fbrown in 3 steps\n",
      "Message terminated at node bethanyturner in 3 steps\n",
      "Message terminated at node bethanyturner in 2 steps\n",
      "Message reached node bethanyturner in 3 steps\n",
      "Message reached node bethanyturner in 4 steps\n",
      "Message reached node bethanyturner in 2 steps\n",
      "Message reached node bethanyturner in 6 steps\n",
      "Message reached node bethanyturner in 3 steps\n",
      "Message reached node bethanyturner in 5 steps\n",
      "Message reached node bethanyturner in 2 steps\n",
      "Message reached node bethanyturner in 3 steps\n",
      "Message reached node bethanyturner in 3 steps\n",
      "Message reached node bethanyturner in 2 steps\n",
      "dannyhoover 0.0012048192771084338\n"
     ]
    }
   ],
   "source": [
    "### From Listing 6-2 ###\n",
    "def run_sim_1(posts):\n",
    "    G = nx.DiGraph()\n",
    "    ### From listing 6-1 ###\n",
    "    XI = [\"send\", None]\n",
    "    k=10\n",
    "    n=10\n",
    "    posts = posts[posts[\"in_reply_to_screen_name\"].notnull()]\n",
    "    for idx in posts.index:\n",
    "        row = posts.loc[idx]\n",
    "        G.add_edge(row[\"in_reply_to_screen_name\"], row[\"user_screen_name\"], capacity=len(row[\"text\"]))\n",
    "    out_deg = G.out_degree()\n",
    "    valkey_sorted = sorted(out_deg, key=lambda x: (x[1], x[0]))\n",
    "    S0 = valkey_sorted[-1][0]\n",
    "    ###################\n",
    "    R = []\n",
    "    for i in range(k):\n",
    "        uq = S0\n",
    "        Tn = []\n",
    "        for j in range(n):\n",
    "            if choice(XI) is not None:\n",
    "                gamma_uq = list(nx.neighbors(G, uq))\n",
    "                if len(gamma_uq) > 1:\n",
    "                    vq = choice(gamma_uq)\n",
    "                    Tn.append((uq, vq))\n",
    "                    uq = vq\n",
    "                elif len(gamma_uq) == 1:\n",
    "                    vq = gamma_uq[0]\n",
    "                    Tn.append((uq, vq))\n",
    "                    uq = vq\n",
    "                else:\n",
    "                    conc = \"Message terminated at node %s in %d steps\"\n",
    "                    print( conc % (uq, len(Tn)))\n",
    "                    break\n",
    "    \n",
    "        R.append((uq, Tn))\n",
    "    tot = 0\n",
    "    for end, path in R:\n",
    "        conc = \"Message reached node %s in %d steps\"\n",
    "        print( conc % (uq, len(path)))\n",
    "        uniq = unique(path)\n",
    "        tot = len(uniq) - 1\n",
    "    print(S0, (tot / len(R)) / (len(G.nodes.keys()) - 1))\n",
    "\n",
    "run_sim_1(post_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell wraps the code from listing 6-3 in a convenience function definition which rerun the simulation for each term you pass in the term_list input parameter. The simulation uses the hub part of the HITS algorithm to determine which node would likely create a post based on the term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### From listing 6-3 ###\n",
    "def run_sim_2(term_list, post_df):\n",
    "    for term in term_list:\n",
    "        R = []\n",
    "        hG = ext.term_subgraph(term, post_df)\n",
    "        hub_scores, auth_scores = nx.hits(hG, max_iter=1000, tol=0.01)\n",
    "        hub_max = max(hub_scores.values())\n",
    "        S0_i = list(hub_scores.values()).index(hub_max)\n",
    "        S0 = list(hub_scores.keys())[S0_i]\n",
    "\n",
    "        for i in range(k):\n",
    "            uq = S0\n",
    "            Tn = []\n",
    "            for j in range(n):\n",
    "                send_msg = ext.hub_send(hub_scores[uq])\n",
    "                if send_msg:\n",
    "                    vq = ext.scored_neighbor_select(hG, uq, auth_scores)\n",
    "                    if vq is None:\n",
    "                        conc = \"Message terminated at node %s in %d steps\"\n",
    "                        print( conc % (uq, len(Tn)))\n",
    "                        break\n",
    "                    else:\n",
    "                        Tn.append((uq, vq))\n",
    "                        uq = vq\n",
    "            R.append((uq, Tn))\n",
    "        ended_at = {}\n",
    "        for end, path in R:\n",
    "            if end in ended_at.keys():\n",
    "                ended_at[end] += 1\n",
    "            else:\n",
    "                ended_at[end] = 1\n",
    "        return (S0, ended_at)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell runs the run_sim_2 function ten times and aggregate the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gutierrezjamie influenced shannon42 an average of 0.90 times\n",
      "gutierrezjamie influenced hartmanmatthew an average of 2.70 times\n",
      "gutierrezjamie influenced garciajames an average of 1.50 times\n",
      "gutierrezjamie influenced iwatkins an average of 2.50 times\n",
      "gutierrezjamie influenced daniel99 an average of 0.60 times\n",
      "gutierrezjamie influenced grosslinda an average of 1.00 times\n"
     ]
    }
   ],
   "source": [
    "### From Listing 6-4 ###\n",
    "all_runs = {}\n",
    "started_at = \"\"\n",
    "k=10\n",
    "n=10\n",
    "for run_i in range(10):\n",
    "    started_at, results = run_sim_2([\"environment\"], post_df)\n",
    "    for ks in results:\n",
    "        if ks in all_runs.keys():\n",
    "            all_runs[ks] += results[ks]\n",
    "        else:\n",
    "            all_runs[ks] = results[ks]\n",
    "for node in all_runs.keys():\n",
    "    if node != started_at:\n",
    "        print(\"%s influenced %s an average of %.2f times\" % (\n",
    "            started_at, node, all_runs[node]/10\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
